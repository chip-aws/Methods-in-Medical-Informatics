{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to chapter nine of Methods in Medical Informatics! In this section, we will be exploring PubMed. PubMed is the U.S National Library of Medicine's public search engine for about 19 million citations from the medical literature. In this chapter, we will be exploring script which allow us to explore PubMed further. Lets begin!\n",
    "\n",
    "> Disclaimer: The content below is adapted from the book \"Methods in Medical Informatics - Fundamental of Healthcare Programming in Perl, Python, and Ruby\" by Jules J. Berman. All content is for testing, education, and teaching purposes only. No content will be openly released to the internet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Building a Large Text Corpus of Biomedical Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is remarkably easy to create a large public domain text corpus fro almost any medical specialty. All you need to do is to enter a PubMed query and and the results to a file on your computer's hard disk.*\n",
    "\n",
    "**Description adapted from pages 131-132 of \"Methods in Medical Informatics\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T18:11:18.259712Z",
     "start_time": "2020-12-02T18:11:17.594817Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import string, re\n",
    "in_text = open(\"cancer_citations.txt\", \"r\", encoding=\"utf-8\")\n",
    "out_text = open(\"cancer_gene_titles.txt\", \"w\")\n",
    "clump = \"\"\n",
    "for line in in_text:\n",
    "    title_match = re.search(r'(?<=TI)(.*)', clump)\n",
    "    if title_match:\n",
    "        title = title_match.group(1)\n",
    "        title = title.lower()\n",
    "        title = re.sub(r'\\'s', \"\", title)\n",
    "        title = re.sub(r'\\W', \" \", title)\n",
    "        title = re.sub(r'omas', \"oma\", title)\n",
    "        title = re.sub(r'tumour', \"tumor\", title)\n",
    "        title = re.sub(r'\\n', \" \", title)\n",
    "        title = title.rstrip()\n",
    "        title = title.lstrip()\n",
    "        title = re.sub(r' +', \" \", title)\n",
    "        text_match = re.search(r'[a-z]+', title)\n",
    "        if not text_match:\n",
    "            clump = \"\"\n",
    "            continue\n",
    "        print(title)\n",
    "        out_text.write(title)\n",
    "        clump = \"\"\n",
    "    else:\n",
    "        clump = clump + line\n",
    "out_text.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Script Algorithm: Building a Large Text Corpus of Biomedical Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Open the PubMed download file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import string, re\n",
    "in_text = open(\"cancer_citations.txt\", \"r\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T20:25:38.176215Z",
     "start_time": "2020-12-06T20:25:38.170232Z"
    },
    "hidden": true
   },
   "source": [
    "Open an output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_text = open(\"cancer_gene_titles.txt\", \"w\")\n",
    "clump = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "PubMed download files contain records that consistently begin with “PMID- ”. Parse through the PubMed download file, record by record, using “PMID- ” as the record separator. Within the record, the title field is preceded by “TI - ”, and the title ends with a newline character followed by another field designator, such as the abstract field designator, “AB - ”. For example: TI—A Wnt Survival Guide: From Flies to Human Disease. AB—It has been two decades since investigators discovered the… From each record, extract the text that lies between the title field designator and the next field designator. Convert the title to lowercase. Clean the title line by removing nonalphanumeric characters, extra spaces, possessive markers (“’s”), and the plural forms of tumor names. Write titles to an external output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for line in in_text:\n",
    "    title_match = re.search(r'(?<=TI)(.*)', clump)\n",
    "    if title_match:\n",
    "        title = title_match.group(1)\n",
    "        title = title.lower()\n",
    "        title = re.sub(r'\\'s', \"\", title)\n",
    "        title = re.sub(r'\\W', \" \", title)\n",
    "        title = re.sub(r'omas', \"oma\", title)\n",
    "        title = re.sub(r'tumour', \"tumor\", title)\n",
    "        title = re.sub(r'\\n', \" \", title)\n",
    "        title = title.rstrip()\n",
    "        title = title.lstrip()\n",
    "        title = re.sub(r' +', \" \", title)\n",
    "        text_match = re.search(r'[a-z]+', title)\n",
    "        if not text_match:\n",
    "            clump = \"\"\n",
    "            continue\n",
    "        print(title)\n",
    "        out_text.write(title)\n",
    "        clump = \"\"\n",
    "    else:\n",
    "        clump = clump + line\n",
    "out_text.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**This section is adapted from section 9.1.1, \"Script Algorithm\", of page 132 from \"Methods in Medical Informatics\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Analysis: Building a Large Text Corpus of Biomedical Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The output is a public domain file consisting of lowercase reference titles, without punctuation. We will use this file in the next section.*\n",
    "\n",
    "**This section is adapted from section 9.1.2, \"Analysis\", of page 134 in \"Methods in Medical Informatics\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Creating a List of Doublets from a PubMed Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Autocoding is a specialized form of machine translation. The general idea behind machine translation is that computers have the patience, stamina, and speed to quickly parse through gigabytes of text, matching text terms with equivalent terms from an external vocabulary. We will be using doublets in later chapters, for a variety of different informatics projects. For all these projects, we will need to create an electronic list of the doublets contained in a text corpus. Let us create a doublet list from the PubMed corpus prepared in the previous section.*\n",
    "\n",
    "**Description adapted from pages 134-136 of \"Methods in Medical Informatics\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T20:43:46.743689Z",
     "start_time": "2020-12-06T20:43:46.570154Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "intext = open(\"cancer_gene_titles.txt\", \"r\")\n",
    "outtext = open(\"doubs.txt\", \"w\")\n",
    "doubhash = {}\n",
    "doublet = \"\"\n",
    "doub_match = re.compile(r'^[a-z]+ [a-z]+$')\n",
    "for line in intext:\n",
    "    line = line.strip()\n",
    "    line_array = re.split(r'\\s+',line)\n",
    "    line_array.append(\"\")\n",
    "    for i in range(len(line_array)-1):\n",
    "        doublet = line_array[i] + \" \" + line_array[i+1]\n",
    "        if doub_match.search(doublet):\n",
    "            doubhash[doublet]=\"\"\n",
    "for k,v in doubhash.items():\n",
    "    text = k + '\\n'\n",
    "    print(k)\n",
    "    outtext.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Script Algorithm: Creating a List of Doublets from a PubMed Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Open a text file. In this case, we will use cancer_gene_titles.txt, a list of\n",
    "titles prepared in Section 9.1. Because the titles of copyrighted works\n",
    "are exempted from copyright restrictions, the file belongs to the public domain.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "intext = open(\"cancer_gene_titles.txt\", \"r\")\n",
    "outtext = open(\"doubs.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Parse through the file, line by line. For each line of the file, parse through every doublet on the line. This means,\n",
    "looking at each two-word doublet consisting of each word in the line, with the\n",
    "word that follows. As each doublet is encountered, add the doublet to a dictionary object. The dictionary\n",
    "object will have doublets as keys and the empty string, “”, as the value for each doublet. Some doublets will occur more than once in the text. A replicate\n",
    "doublet will generate a preexisting key–value pair and will not increase\n",
    "the size of the dictionary object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "doubhash = {}\n",
    "doublet = \"\"\n",
    "doub_match = re.compile(r'^[a-z]+ [a-z]+$')\n",
    "for line in intext:\n",
    "    line = line.strip()\n",
    "    line_array = re.split(r'\\s+',line)\n",
    "    line_array.append(\"\")\n",
    "    for i in range(len(line_array)-1):\n",
    "        doublet = line_array[i] + \" \" + line_array[i+1]\n",
    "        if doub_match.search(doublet):\n",
    "            doubhash[doublet]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After the text is parsed, print out the keys of the dictionary object to an external\n",
    "file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for k,v in doubhash.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**This section is adapted from section 9.2.1, \"Script Algorithm\", of pages 136-137 from \"Methods in Medical Informatics\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Analysis: Creating a List of Doublets from a PubMed Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Analysis\n",
    "The output file, doubs.txt is >24,000 bytes in length and contains thousands of doublets.\n",
    "A few doublet entries from the output file are shown:\n",
    "somatic mutational\n",
    "mutational landscape\n",
    "landscape in\n",
    "in sporadic\n",
    "sporadic human\n",
    "deficient tumors\n",
    "tumors diagnostic\n",
    "diagnostic features\n",
    "features and\n",
    "and molecular\n",
    "molecular geneticsclinical\n",
    "geneticsclinical actionability\n",
    "actionability of\n",
    "of molecular\n",
    "molecular targets\n",
    "When the original text has no identifying, misspelled, profane, or otherwise objectionable\n",
    "text, the resulting doublets can be used as “safe” for inclusion in confidential\n",
    "text (see Chapter 15). In this case, we extracted doublets from a corpus consisting of\n",
    "the titles of scientific articles. These titles would not be expected to contain identifying\n",
    "or objectionable doublets.*\n",
    "\n",
    "**This section is adapted from section 9.2.2, \"Analysis\", of pages 138-139 from \"Methods in Medical Informatics\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Downloading Gene Synonyms from PubMed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " At the pubmed site (https://www.ncbi.nlm.nih.gov/gene/), select \"Gene\" as your Search engine, and enter \"geneid\" as your query. Pubmed will return a large set of geneid entries which you can download. The records serve as a text corpus form which you can extract a gene nomenclature*\n",
    " \n",
    "**Description adapted from page 139 of \"Methods in Medical Informatics\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Downloading Protein Synonyms from PubMed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Select the “Protein” database (https://www.ncbi.nlm.nih.gov/protein/), and enter the query:\n",
    "- <p>((protein AND human) AND “Homo sapiens”[porgn:__txid9606]) AND “Homo sapiens”[porgn:__txid9606]</p>\n",
    "In this example, the results yielded 1,392,492 entries. It is easy to see that the output file\n",
    "can be easily parsed, and protein information can be integrated with any other data\n",
    "sets that contain information on any virtually any protein.*\n",
    "\n",
    "**Description adapted from page 140 of \"Methods in Medical Informatics\"*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
