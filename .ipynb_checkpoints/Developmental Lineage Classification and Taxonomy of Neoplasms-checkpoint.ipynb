{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Building the Doublet Hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The utility of the doublet method is derived in part from the observation that most\n",
    "medical terms are multiword terms. In the Neoplasm Classification, all but about\n",
    "250 terms are multiword terms. Unlike single words, which often have several different\n",
    "meanings, multiword medical terms, with very rare exceptions, have a single,\n",
    "specific meaning.\n",
    "In Chapter 9, Section 9.2, we learned that any multiword term can be constructed\n",
    "by a concatenation of overlapping doublets.\n",
    "For example:\n",
    "Serous borderline ovarian tumor -> (“serous borderline,” “borderline ovarian,”\n",
    "“ovarian tumor”)\n",
    "The doublets composing the multiword terms from the neoplasm nomenclature can\n",
    "be combined into a list. The list of nomenclature doublets can be used to determine\n",
    "whether a fragment of text is composed from doublets included in the list.\n",
    "We would like to build a persistent data object (see Chapter 5, Section 5.2) containing\n",
    "all of the doublet terms found in the Neoplasm Classification. We will use the\n",
    "doublet list for a variety of informatics projects featured in this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T21:18:38.177246Z",
     "start_time": "2020-11-22T20:04:08.266980Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import dbm, string, re\n",
    "doubhash = dbm.open('doub', 'n')\n",
    "literalhash = dbm.open('literal', 'n')\n",
    "in_file = open('./K11946_Files/NEOCL.XML', \"r\")\n",
    "singular = re.compile('omas')\n",
    "england = re.compile('tumou?rs?')\n",
    "phrase = \"\"\n",
    "for line in in_file:\n",
    "    print(1)\n",
    "    neoplasm_match = re.search(r'\\\"\\> ?(.+) ?\\<', line)\n",
    "    if neoplasm_match:\n",
    "        print(2)\n",
    "        phrase = neoplasm_match.group(1)\n",
    "        phrase = singular.sub(\"oma\",phrase)\n",
    "        phrase = england.sub(\"tumor\",phrase)\n",
    "        literalhash[phrase] = \"\"\n",
    "    print(4)\n",
    "    hoparray = phrase.split()\n",
    "    print(5)\n",
    "    hoparray.append(\" \")\n",
    "    print(6)\n",
    "    for i in range(len(hoparray)-1):\n",
    "        print(7)\n",
    "        doublet = hoparray[i] + \" \" + hoparray[i + 1]\n",
    "        print(8)\n",
    "        if doublet in doubhash:\n",
    "            continue\n",
    "        doubhash_match = re.search(r'[a-z]+ [a-z]+', doublet)\n",
    "        print(9)\n",
    "        if doubhash_match:\n",
    "            print(10)\n",
    "            doubhash[doublet] = \"\"\n",
    "doubhash.close()\n",
    "literalhash.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Script Algorithm: Building the Doublet Hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Create two external database objects.\n",
    "2. We will tie one external database object to a dictionary object composed of\n",
    "key–value pairs, where the keys are the neoplasm terms in the Neoplasm\n",
    "Classification, and the values are the empty character (“ ”).\n",
    "3. We will tie another external database object to a dictionary object composed\n",
    "of key–value pairs, where the keys are the collection of word doublets from the\n",
    "Neoplasm Classification, and the values are the empty character (“ ”).\n",
    "4. Open the Neoplasm Classification for parsing. The compressed file is available\n",
    "for download at\n",
    "http://www.julesberman.info/neoclxml.gz.\n",
    "Make certain that the unzipped file is named neocl.xml and that your script\n",
    "lists its correct subdirectory location on your computer.\n",
    "5. Parse through the file, line by line.\n",
    "6. Neoplasm terms are flanked by angle brackets and can be extracted with a\n",
    "simple regex expression.\n",
    "7. The neoplasm term is added as a new key to the dictionary object containing\n",
    "the terms in the nomenclature.\n",
    "8. The term is parsed into doublets by iterating through each word in the term\n",
    "and appending the next consecutive word. Add each doublet term to the dictionary\n",
    "object containing word doublets as keys.\n",
    "9. After the entire nomenclature file is parsed, the two dictionary objects achieve\n",
    "persistence through the external database objects to which they were tied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Analysis: Building the Doublet Hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We now have persistent data objects in external database files (i.e., the terms object\n",
    "and the doublets object) that we can use in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Scanning the Literature for Candidate Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here is a simple method for extracting candidate new terms from any large corpus\n",
    "of text.\n",
    "The method depends on the empirical observation that terms in a nomenclature are composed\n",
    "almost exclusively of doublets found in other terms in the same nomenclature.\n",
    "The current version of the neoplasm nomenclature contains 135,000 unique terms.\n",
    "Of these terms, 126,756 terms are classified terms and are composed of at least two\n",
    "words (i.e., are doublets or greater in length). Of these 126,756 terms, all but 6,308\n",
    "(4.97%) are composed entirely of doublets extracted from other terms in the reference\n",
    "nomenclature. This means that 95% of the classified terms from the nomenclature are\n",
    "formed entirely of doublet terms found in other terms from the same nomenclature.\n",
    "The method compares connected word doublets in a medical text against a list of\n",
    "word doublets found in a nomenclature. Text phrases composed of sequences of word\n",
    "doublets found in an existing nomenclature are candidate new nomenclature terms.\n",
    "This general method can be used with any text and any existing nomenclature. This\n",
    "method permits curators to continually enhance their nomenclatures with new terms,\n",
    "an essential activity needed to ensure the proper coding and annotation of biomedical\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T21:18:38.179205Z",
     "start_time": "2020-11-22T20:09:14.475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import dbm, string, re\n",
    "doubhash = dbm.open('doub')\n",
    "literalhash = dbm.open('literal')\n",
    "newhash = {}\n",
    "in_file = open('./K11946_File/cancer_gene_titles.txt', 'r')\n",
    "line = \" \"\n",
    "count = 0\n",
    "singular = re.compile('omas')\n",
    "england = re.compile('tumou?rs?')\n",
    "for line in in_file:\n",
    "    bigline = line.rstrip(\" \\n\")\n",
    "    bigline = singular.sub(\"oma\", bigline)\n",
    "    bigline = england.sub(\"tumor\", bigline)\n",
    "    englishline = \"\"\n",
    "    hoparray = bigline.split()\n",
    "    hoparray.append(\" \")\n",
    "    for i in range(len(hoparray) - 1):\n",
    "        doublet = hoparray[i] + \" \" + hoparray[i + 1]\n",
    "        if doubhash.has_key(doublet):\n",
    "            if (englishline != \"\"):\n",
    "                englishline = englishline + \" \" + hoparray[i + 1]\n",
    "            else:\n",
    "                englishline = doublet\n",
    "        else:\n",
    "            if englishline != \"\":\n",
    "                englishline = englishline.strip()\n",
    "                englishline = re.sub(r'^the ', \"\", englishline)\n",
    "                englishline = re.sub(r'^in ', \"\", englishline)\n",
    "                englishline = re.sub(r'^of ', \"\", englishline)\n",
    "                englishline = re.sub(r'^and ', \"\", englishline)\n",
    "                englishline = re.sub(r'^with ', \"\", englishline)\n",
    "                englishline = re.sub(r'^from ', \"\", englishline)\n",
    "                englishline = re.sub(r'^ a', \"\", englishline)\n",
    "                englishline = re.sub(r' the$', \"\", englishline)\n",
    "                englishline = re.sub(r' in$', \"\", englishline)\n",
    "                englishline = re.sub(r' of$', \"\", englishline)\n",
    "                englishline = re.sub(r' and$', \"\", englishline)\n",
    "                englishline = re.sub(r' with$', \"\", englishline)\n",
    "                englishline = re.sub(r' from$', \"\", englishline)\n",
    "                englishline = re.sub(r' a$', \"\", englishline)\n",
    "                if literalhash.has_key(englishline):\n",
    "                    continue\n",
    "                if newhash.has_key(englishline):\n",
    "                    continue\n",
    "                phrase_match = re.search(r' [a-z]+ ', englishline)\n",
    "                if phrase_match:\n",
    "                    count = count + 1\n",
    "                    print str(count) + \" \" + englishline\n",
    "                    newhash[englishline] = \"\"\n",
    "doubhash.close()\n",
    "literalhash.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Script Algorithm: Scanning the Literature for Candidate Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Collect all the doublets that occur in the entire nomenclature (i.e., use the\n",
    "database object created in Section 11.1).\n",
    "2. Parse text (in this case individual abstract titles) into an ordered array of\n",
    "overlapping doublets (as per the example shown for the text string, “serous\n",
    "borderline ovarian tumor”).\n",
    "The text file that we use is cancer_gene_titles.txt (1,752,432 bytes), created\n",
    "in Chapter 9, Section 9.1. It contains 28,102 titles related to the topic of genes\n",
    "and cancer or tumors. It is available for download at\n",
    "http://www.julesberman.info/book/cancer_gene_titles.txt.\n",
    "Alternatively, you can create your own file of titles by downloading a\n",
    "PubMed search on a topic of your own interest and collecting the titles, using\n",
    "the script provided in the previous section.\n",
    "3. Compare each consecutive text doublet against the array of doublets from\n",
    "the nomenclature to determine whether the doublet exists somewhere in the\n",
    "nomenclature.\n",
    "4. If the doublet from the text does not exist in the nomenclature, it can be\n",
    "deleted. If it exists in the nomenclature, it is concatenated with the following\n",
    "doublet if the following doublet exists in the nomenclature. Otherwise, it is\n",
    "deleted. This process continues, concatenating doublets that exist somewhere\n",
    "in the nomenclature. Extraneous leading words (the, in, of, with, and) and\n",
    "trailer words (the, and, with, from, a) are automatically deleted from the final\n",
    "concatenated sequence. Final concatenated sequences of two or greater consecutive\n",
    "doublets that match to doublets from the nomenclature are saved as\n",
    "candidate terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Analysis: Scanning the Literature for Candidate Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Parsing the file cancer_genes_titles.txt, we found about 4,100 new candidate neoplasm\n",
    "terms. Here are some final terms from the output list:\n",
    "intraneural perineurioma of the oral mucosa\n",
    "due to promyelocytic leukemia\n",
    "spinal cord primary extragonadal\n",
    "spinal cord primary extragonadal sac tumor\n",
    "epithelioid and spindle cell haemangioma of bone\n",
    "cervical malformation neurofibromatosis type 1\n",
    "osteoblastoma of the scapula\n",
    "ameloblastic carcinoma in\n",
    "pancreatic serous cystadenoma endocrine tumor\n",
    "extrarenal rhabdoid tumor of the cervical spine\n",
    "diffuse type cell tumor of the subcutaneous\n",
    "ewing sarcoma neuroectodermal tumor of the kidney\n",
    "low grade fibromyxoid sarcoma of the colon\n",
    "inflammatory myofibroblastic tumor of the tongue\n",
    "superficial angiomyxoma the floor of the mouth\n",
    "young adult with acute lymphoblastic leukemia\n",
    "burkitt lymphoma in pediatric\n",
    "peripheral primitive neuroectodermal tumor of the maxilla\n",
    "anaplastic large cell lymphoma of bone\n",
    "A cursory examination of this small portion of the 4077 returned candidate terms\n",
    "indicates that some of the terms seem to be legitimate names of neoplasms, which\n",
    "should be added to our neoplasm vocabulary:\n",
    "intraneural perineurioma of the oral mucosa\n",
    "epithelioid and spindle cell haemangioma of bone\n",
    "osteoblastoma of the scapula\n",
    "pancreatic serous cystadenoma endocrine tumor\n",
    "extrarenal rhabdoid tumor of the cervical spine\n",
    "low grade fibromyxoid sarcoma of the colon\n",
    "inflammatory myofibroblastic tumor of the tongue\n",
    "peripheral primitive neuroectodermal tumor of the maxilla\n",
    "anaplastic large cell lymphoma of bone\n",
    "The majority of terms are phrases that happen to consist of doublets from our nomenclature,\n",
    "but do not rise to the level of a new neoplasm term:\n",
    "due to promyelocytic leukemia\n",
    "spinal cord primary extragonadal\n",
    "spinal cord primary extragonadal sac tumor\n",
    "cervical malformation neurofibromatosis type 1\n",
    "ameloblastic carcinoma in\n",
    "diffuse type cell tumor of the subcutaneous\n",
    "ewing sarcoma neuroectodermal tumor of the kidney\n",
    "young adult with acute lymphoblastic leukemia\n",
    "burkitt lymphoma in pediatric\n",
    "There was one term that seems to be a poorly worded representation of a proper neoplasm’s\n",
    "name:\n",
    "superficial angiomyxoma the floor of the mouth\n",
    "It should be\n",
    "superficial angiomyxoma of the floor of the mouth\n",
    "The original file of abstracts that contained the words cancer and gene exceeded\n",
    "213 megabytes (MB) in length. The perfect curator would have read each abstract,\n",
    "writing down the names of neoplasms that were not contained in the nomenclature.\n",
    "The modern curator had the option of extracting the titles from the articles, and parsing\n",
    "through the titles, extracting about 4,100 candidate terms, and then examining\n",
    "the candidate terms to find likely new terms for the nomenclature. The semiautomated\n",
    "process takes about one-half hour and provides hundreds of new terms that can be\n",
    "added to the nomenclature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Adding Terms to the Neoplasm Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One of the most common tasks in informatics is the preparation of a subtraction list\n",
    "(items present in one list and absent from another).\n",
    "Curators need to prepare a subtraction list whenever they want to add terms to a\n",
    "preexisting nomenclature. The list of candidate terms must be checked against the list\n",
    "of terms found in the nomenclature, with removal of redundant terms in the new list.\n",
    "We can use the Neoplasm Classification as a sample nomenclature. We will use the\n",
    "file neocl.lst (available at http://www.julesberman.info/book/neocl/lst), which contains\n",
    "the following list of candidate terms:\n",
    "prostate cancer\n",
    "adenocarcinoma of prostate\n",
    "spiradenocylindroma of the kidney\n",
    "spiradenocylindroma\n",
    "pleomorphic myxoid liposarcoma\n",
    "spindle cell myxoid liposarcoma\n",
    "matrix producing carcinoma of breast\n",
    "matrix producing carcinoma of the breast\n",
    "dini of breast\n",
    "precancer flat epithelial atypia\n",
    "matrix-producing carcinoma of the breast\n",
    "early onset cancer\n",
    "early-onset neoplasm\n",
    "early-onset neoplasia\n",
    "carcinoma of the bellini collecting duct\n",
    "adenocarcinoma of the prostate\n",
    "We need to know which terms, among the candidate terms, are already included in\n",
    "the Neoplasm Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T21:18:38.181200Z",
     "start_time": "2020-11-22T20:09:16.325Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "vocab_in = open('./K11946_Files/NEOCL.XML', \"r\")\n",
    "doub_hash = {}\n",
    "for line in vocab_in:\n",
    "    code_match = re.search(r'C[0-9]{7}', line)\n",
    "    if not code_match:\n",
    "        continue\n",
    "    line_match = re.search(r'\\”\\> ?(.+) ?\\<\\/', line)\n",
    "    if line_match:\n",
    "        phrase = line_match.group(1)\n",
    "        doub_hash[phrase] = \"\"\n",
    "vocab_in.close()\n",
    "candidate_file = open('./K11946_Files/neocl.lst', \"r\")\n",
    "out_file = open(\"new.out\", \"w\")\n",
    "for line in candidate_file:\n",
    "    line = re.sub(r'\\n',\"\", line)\n",
    "    if (line == \"\"):\n",
    "        continue\n",
    "    if line in doub_hash:\n",
    "        print line + \" already exists\"\n",
    "    else:\n",
    "        print(out_file, line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Script Algorithm: Adding Terms to the Neoplasm Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Open the Neoplasm Classification file.\n",
    "2. Parse through the file, collecting every code/term pair in the Neoplasm\n",
    "Classification, and assigning each pair as the key and value (respectively) for a\n",
    "dictionary object.\n",
    "3. Open the file containing the list of candidate terms to be added to the\n",
    "Neoplasm Classification.\n",
    "4. Parse each term from the list, checking to see if it is already contained as a key\n",
    "in the dictionary object.\n",
    "5. For each term, if the term does not already exist as a key in the dictionary\n",
    "object, print it to an external file.\n",
    "6. After the script executes, you have a new file containing terms that can be\n",
    "added to the Neoplasm Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Analysis: Adding Terms to the Neoplasm Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The script splits the output into the set of terms already contained in the Neoplasm\n",
    "Classification, displayed on the computer monitor:\n",
    "prostate cancer already exists\n",
    "adenocarcinoma of prostate already exists\n",
    "spiradenocylindroma of the kidney already exists\n",
    "matrix producing carcinoma of breast already exists\n",
    "matrix producing carcinoma of the breast already exists\n",
    "matrix-producing carcinoma of the breast already exists\n",
    "adenocarcinoma of the prostate already exists\n",
    "And an output file, containing the list of terms that are not already included in the\n",
    "Neoplasm Classification:\n",
    "spiradenocylindroma\n",
    "pleomorphic myxoid liposarcoma\n",
    "spindle cell myxoid liposarcoma\n",
    "dini of breast\n",
    "precancer-flat epithelial atypia\n",
    "early onset cancer\n",
    "early-onset neoplasm\n",
    "early-onset neoplasia\n",
    "carcinoma of the bellini collecting duct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Determining the Lineage of Every Neoplasm Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Biological classifications drive down the complexity of nomenclatures by assigning\n",
    "every term to a class of objects that contain similar features, inherited from a lineage\n",
    "of ancestral objects. We have seen, in the prior chapter, that knowing the lineages of\n",
    "organisms can lead to treatments for newly encountered pathogens. Similarly, knowing\n",
    "the lineage of neoplasms may help us find the tumors most likely to respond, as\n",
    "a biological class, to molecular-targeted cancer treatments. The importance of tumor\n",
    "lineage is one of the important concepts discussed in my book, Neoplasms: Principles of\n",
    "Development and Diversity (Jones & Bartlett Publishers, 2009).\n",
    "The Neoplasm Classification contains about 135,000 names of neoplasms, organized\n",
    "under about 6,000 concepts. A concept is the collection of synonyms for a specific\n",
    "type of neoplasm. Every neoplasm term and concept can be assigned a unique\n",
    "position within a simple class hierarchy, consisting of several dozen ancestral classes\n",
    "(Figure 11.1).\n",
    "The Neoplasm Classification is packaged as an XML (eXtensible Markup Language)\n",
    "file. The terms in the nomenclature are marked up with tags that provide each term\n",
    "with a code number describing each term. Each term in the Neoplasm Classification\n",
    "is nested under another element that names a class of neoplasms. Each named class of\n",
    "neoplasms is nested under elements for the father of the class, and this nesting continues\n",
    "up the classification hierarchy.\n",
    "XML is a markup language created for the Internet, and data that is delivered\n",
    "in XML files permits us to search for related information located anywhere in the\n",
    "Internet. In Chapter 18, we will be describing XML in much more detail. For now,\n",
    "we will take advantage of language-specific modules designed to parse XML, and we will determine the full neoplasm lineage for every term contained in the Neoplasm\n",
    "Classification. If you are unfamiliar with XML, you can skip this section of the chapter\n",
    "and come back to it after reading Chapter 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T21:18:38.182198Z",
     "start_time": "2020-11-22T20:09:18.038Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import xml.parsers.expat\n",
    "import re\n",
    "parsefile = open('./K11946_Files/NEOCL.XML', \"r\")\n",
    "filestring = parsefile.read()\n",
    "lastname = \"\"\n",
    "code = \"\"\n",
    "count = 0\n",
    "text = \"\"\n",
    "def start_element(name, attrs):\n",
    "    global lastname\n",
    "    global code\n",
    "    if attrs.has_key(\"nci-code\"):\n",
    "        code = attrs[\"nci-code\"]\n",
    "    else:\n",
    "        lastname = name + \">\" + lastname\n",
    "def end_element(name):\n",
    "    global count\n",
    "    global code\n",
    "    global text\n",
    "    global lastname\n",
    "    if name == \"name\":\n",
    "        count = count + 1\n",
    "        print str(count) + \"|\" + text + \"|\" + code + \"|\" + lastname + \"\\n\"\n",
    "        text = \"\"\n",
    "    lastname = re.sub(name + r'>','', lastname)\n",
    "def char_data(data):\n",
    "    global text\n",
    "    text = repr(data)\n",
    "    textmatch = re.search(r'\\'(.+)\\'',text)\n",
    "    if textmatch:\n",
    "        text = textmatch.group(1)\n",
    "p = xml.parsers.expat.ParserCreate()\n",
    "p.StartElementHandler = start_element\n",
    "p.EndElementHandler = end_element\n",
    "p.CharacterDataHandler = char_data\n",
    "p.Parse(filestring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Script Algorithm: Determining the Lineage of Every Neoplasm Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Call the XML parser module into your script.\n",
    "2. Define subroutines that process XML information for specific events that\n",
    "occur as the XML file is parsed. These events happen whenever the script\n",
    "encounters the start of an XML element; the script encounters the end of an\n",
    "XML element; and the script encounters the data described by the XML tag.\n",
    "3. Provide the parser object with the name of the XML file that you would like\n",
    "to parse. In this case, it is the neocl.xml file.\n",
    "4. When an element is encountered, the parser passes the name of the element\n",
    "and any attributes within the element (in this case, the code number for the\n",
    "term) to a list of variables. When the data contents of the element are encountered,\n",
    "the parser passes the data to a variable. In this case, the data associated\n",
    "with an element is the neoplasm term.\n",
    "5. As the parser works its way down the hierarchy, it concatenates the names of\n",
    "the ancestors into a string. When it finally encounters the lowest element in the hierarchy, it concatenates the data (the name of the term), and the attribute\n",
    "(the code for the term), appends the hierarchical list of elements (ancestors) to\n",
    "the string, and prints it to an external file. When it backs up through the hierarchy\n",
    "(when it moves through different class lineages), it truncates the previously\n",
    "built string of concatenated classes to exclude nonancestral classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Analysis: Determining the Lineage of Every Neoplasm Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The neocl.xml file is over 10 MB in length. It takes several seconds, on most computers\n",
    "(with 2–3 GHz CPUs) to run this script, producing an output file that exceeds\n",
    "17 MB in length. Here are a few lines of the output file:\n",
    "\n",
    "1|teratoma|C3403000|totipotent_or_multipotent_differentiating>\n",
    "primitive_differentiating>primitive>embryonic>neoplasms>\n",
    "tumor_classification>\n",
    "2|embryonal ca|C3752000|totipotent_or_multipotent_differentiating>\n",
    "primitive_differentiating>primitive>embryonic>neoplasms>\n",
    "tumor_classification>\n",
    "3|embryonal cancer|C3752000|totipotent_or_multipotent_differentiating>\n",
    "primitive_differentiating>primitive>embryonic>neoplasms>\n",
    "tumor_classification>\n",
    "4|embryonal carcinoma|C3752000|totipotent_or_multipotent_differentiating>\n",
    "primitive_differentiating>primitive>embryonic>neoplasms>\n",
    "tumor_classification>\n",
    "\n",
    "Because we know the structure of the Neoplasm Classification file, we could have\n",
    "written a parsing script without using an external XML parser, if we had so chosen.\n",
    "The script would have been similar to the script that we used to find the lineage of\n",
    "organisms from the Taxonomy.dat file (Chapter 10). However, because the neocl.xml\n",
    "file is created as an XML file, it is better to use the readily available XML parsing\n",
    "module. Doing so shortens our script and, if you do much work with XML, is easy\n",
    "to read. Once you have learned to parse XML files, you will be able to write scripts\n",
    "that collect, transform, and analyze data from multiple, different XML files, collected\n",
    "from anywhere on the Internet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
